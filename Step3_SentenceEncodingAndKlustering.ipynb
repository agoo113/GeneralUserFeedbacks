{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence emcoding and Clustering\n",
    "This file processes feedbacks or feedback sentences after sentimental analysis. \n",
    "It focuses on processing feedbacks that are negative to try to extract more useful information out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sentiment processed feedback files\n",
    "The purpose of clustering is to properly classify problems highlighted by the users on Windows Update. \n",
    "We should only look at comments where people are stating problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "fileToProcess = \"Negative_CleanedFeedbackSentences.csv\"\n",
    "\n",
    "dataset = pd.read_csv(fileToProcess)\n",
    "print(dataset.info())\n",
    "feedbackSentences = dataset['0'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Encoding\n",
    "\n",
    "Text are in strings and need to be encoded into uniformed vectors first before clustering step\n",
    "### ref: \n",
    "- https://towardsdatascience.com/an-intuitive-explanation-of-sentence-bert-1984d144a868\n",
    "- https://www.sbert.net/docs/installation.html\n",
    "- https://www.sbert.net/docs/package_reference/SentenceTransformer.html\n",
    "- https://www.sbert.net/docs/pretrained_models.html#model-overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') # pre-trained model to encode: https://www.sbert.net/docs/pretrained_models.html#model-overview\n",
    "\n",
    "#encode the sentences\n",
    "feedbackEmbeddings = model.encode(feedbackSentences, convert_to_tensor=True, normalize_embeddings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to comp sentence encoding in cos similarity\n",
    "def PairsToCompareEncoding(i_feedbackEmbeddings, i_feedbackSentences, rangeLimit, printLimit):\n",
    "    #compute the similarity scores\n",
    "    cosine_scores = util.cos_sim(i_feedbackEmbeddings, i_feedbackEmbeddings)\n",
    "    i_feedbackEmbeddingsValue = i_feedbackEmbeddings.values\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(100):\n",
    "        for j in range(i+1, 101):\n",
    "            pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "            \n",
    "    #sort the scores in decreasing order \n",
    "    pairs = sorted(pairs, key=lambda i_feedbackEmbeddingsValue: i_feedbackEmbeddingsValue['score'], reverse=True)\n",
    "    for i in range(100):\n",
    "        for j in range(i+1, 101):\n",
    "            pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "    #sort the scores in decreasing order \n",
    "    pairs = sorted(pairs, key=lambda i_feedbackEmbeddingsValue: i_feedbackEmbeddingsValue['score'], reverse=True)\n",
    "\n",
    "    print(\"Non-related--------------------------------------------------------------------------------------------\")\n",
    "    for pair in pairs[-1*printLimit:]:\n",
    "        i, j = pair['index']\n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(i_feedbackSentences[i], i_feedbackSentences[j], pair['score']))#\n",
    "    print(\"Related-------------------------------------------------------------------------------------------------\")\n",
    "    for pair in pairs[0:printLimit]:\n",
    "        i, j = pair['index']        \n",
    "        print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(i_feedbackSentences[i], i_feedbackSentences[j], pair['score']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PairsToCompareEncoding(feedbackEmbeddings,feedbackSentences, 100, 20 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Clustering\n",
    "- k means is good to roughly divide the data into equal parts.\n",
    "- The nature of feedbacks here is people might complain about something more than the others. \n",
    "- Below are sample code how to do a k-mean cluster. \n",
    "- With this method, we might be able to separate general comments vs detailed comments.\n",
    "- ref: https://en.wikipedia.org/wiki/Cluster_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedbackEmbeddingsValue = feedbackEmbeddings.numpy()\n",
    "\n",
    "#finding optimal number of clusters using the elbow method  \n",
    "wcss_list= []  #Initializing the list for the values of WCSS  \n",
    "\n",
    "maxClusterTry = 15\n",
    "#Using for loop for iterations from 1 to 10.  \n",
    "for i in range(1, maxClusterTry):  \n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state= 1)  \n",
    "    kmeans.fit(feedbackEmbeddingsValue)  \n",
    "    wcss_list.append(kmeans.inertia_)  \n",
    "plt.plot(range(1, maxClusterTry), wcss_list)  \n",
    "plt.title('The Elobw Method Graph')  \n",
    "plt.xlabel('Number of clusters(k)')  \n",
    "plt.ylabel('wcss_list')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the K-means model on a dataset \n",
    "numCluster = 10\n",
    "kmeans = KMeans(n_clusters=numCluster, init='k-means++', random_state= 1)  \n",
    "y_predict= kmeans.fit_predict(feedbackEmbeddingsValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_predict, return_counts=True)\n",
    "np.asarray((unique, counts)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteredData = pd.DataFrame({'text' : feedbackSentences, 'clusterLabel' : y_predict}, columns = ['text', 'clusterLabel'])\n",
    "outputFile = \"cluster\" + str(numCluster) + \".csv\"\n",
    "clusteredData.to_csv(outputFile, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization with Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotWordCloud(text):\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"update\", \"updates\", \"upgraded\",\"upgrades\" ,\"windows\", \"window\", \"microsoft\", \"computer\", \"win\", \"upgrade\", \"PC\", \"will\", \"take\", \"even\", \"work\", \"think\", \"laptop\", \"use\"\n",
    "    ])\n",
    "    # Create and generate a word cloud image:\n",
    "    wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, numCluster):\n",
    "    group = feedbackSentences[y_predict == i]\n",
    "    text = \" \".join(review for review in group)\n",
    "    plotWordCloud(text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "efedefd613a9d0d6be0483e7770e06f8d402c2a7509d4785616946f786adc79f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
